{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/megatron/Megatron-LM-working\n"
     ]
    }
   ],
   "source": [
    "cd /workspace/megatron/Megatron-LM-working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'xlnet-Pytorch'...\n",
      "remote: Enumerating objects: 74, done.\u001b[K\n",
      "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
      "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
      "remote: Total 74 (delta 37), reused 58 (delta 21), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (74/74), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/graykode/xlnet-Pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/megatron/Megatron-LM-working/xlnet/xlnet-Pytorch\n"
     ]
    }
   ],
   "source": [
    "cd xlnet-Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_pretrained_bert\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 252kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (1.16.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (2.21.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (2018.1.10)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (4.31.1)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (1.10.45)\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (1.1.0a0+828a6a3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (2019.3.9)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (1.24.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch_pretrained_bert) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.45 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch_pretrained_bert) (1.13.45)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.45->boto3->pytorch_pretrained_bert) (2.8.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.45->boto3->pytorch_pretrained_bert) (0.14)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.45->boto3->pytorch_pretrained_bert) (1.12.0)\n",
      "Installing collected packages: pytorch-pretrained-bert\n",
      "Successfully installed pytorch-pretrained-bert-0.6.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0a0+828a6a3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.backends.cudnn as cudnn\n",
    "torch.backends.cudnn.enabled = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/megatron/Megatron-LM-working\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/megatron/Megatron-LM-working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE\t\t   detokenizer.py\tlog.txt\t\t  pretrain_bert.py\r\n",
      "README.md\t   docker\t\tlogsrs.txt\t  pretrain_gpt2.py\r\n",
      "__pycache__\t   evaluate_gpt2.py\tmodel\t\t  pretrain_xlnet.py\r\n",
      "arguments.py\t   fp16\t\t\tmpu\t\t  requirements.txt\r\n",
      "cache\t\t   generate_samples.py\tnotebooks\t  scripts\r\n",
      "configure_data.py  gpt2_data_loader.py\tnsight_op\t  utils.py\r\n",
      "data\t\t   hugface\t\tnsight_op.qdstrm  xlnet\r\n",
      "data_utils\t   learning_rates.py\topenwebtext\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE\t\t   detokenizer.py\tlog.txt\t\t  pretrain_bert.py\r\n",
      "README.md\t   docker\t\tlogsrs.txt\t  pretrain_gpt2.py\r\n",
      "__pycache__\t   evaluate_gpt2.py\tmodel\t\t  pretrain_xlnet.py\r\n",
      "arguments.py\t   fp16\t\t\tmpu\t\t  requirements.txt\r\n",
      "cache\t\t   generate_samples.py\tnotebooks\t  scripts\r\n",
      "checkpoints\t   gpt2_data_loader.py\tnsight_op\t  utils.py\r\n",
      "configure_data.py  hugface\t\tnsight_op.qdstrm  xlnet\r\n",
      "data_utils\t   learning_rates.py\topenwebtext\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/megatron/integrate-paralllel/Megatron-LM-mp/xlnet\n",
      "PATH:  /workspace/megatron/Megatron-LM/data_utils/data/midrange_data/wikidumpline_AA.json\n",
      "PATH:  /workspace/megatron/Megatron-LM/data_utils/data/midrange_data/wikidumpline_AA.json\n",
      "PATH:  /workspace/megatron/Megatron-LM/data_utils/data/midrange_data/wikidumpline_AA.json\n",
      "PATH:  /workspace/megatron/Megatron-LM/data_utils/data/midrange_data/wikidumpline_AA.json\n",
      "device= 1\n",
      "local 1\n",
      "device= 2\n",
      "local 2\n",
      "device= 3\n",
      "local 3\n",
      "using world size: 4 and model-parallel size: 2 \n",
      " > using dynamic loss scaling\n",
      "device= 0\n",
      "local 0\n",
      "3 range(2, 4)\n",
      "1 range(0, 2)\n",
      "2 range(2, 4)\n",
      "> initializing model parallel with size 2\n",
      "0 range(0, 2)\n",
      "Pretrain GPT2 model\n",
      "arguments:\n",
      "  pretrained_bert .............. False\n",
      "  attention_dropout ............ 0.1\n",
      "  num_attention_heads .......... 16\n",
      "  hidden_size .................. 1024\n",
      "  intermediate_size ............ None\n",
      "  num_layers ................... 24\n",
      "  layernorm_epsilon ............ 1e-05\n",
      "  hidden_dropout ............... 0.1\n",
      "  max_position_embeddings ...... 512\n",
      "  vocab_size ................... 30522\n",
      "  deep_init .................... False\n",
      "  make_vocab_size_divisible_by . 128\n",
      "  fp16 ......................... False\n",
      "  fp32_embedding ............... False\n",
      "  fp32_layernorm ............... False\n",
      "  fp32_tokentypes .............. False\n",
      "  fp32_allreduce ............... False\n",
      "  hysteresis ................... 2\n",
      "  loss_scale ................... None\n",
      "  loss_scale_window ............ 1000\n",
      "  min_scale .................... 1\n",
      "  batch_size ................... 1\n",
      "  weight_decay ................. 0.01\n",
      "  checkpoint_activations ....... False\n",
      "  checkpoint_num_layers ........ 1\n",
      "  clip_grad .................... 1.0\n",
      "  train_iters .................. 1000000\n",
      "  log_interval ................. 100\n",
      "  exit_interval ................ None\n",
      "  tensorboard_dir .............. None\n",
      "  seed ......................... 1234\n",
      "  reset_position_ids ........... False\n",
      "  reset_attention_mask ......... False\n",
      "  eod_mask_loss ................ False\n",
      "  lr_decay_iters ............... None\n",
      "  lr_decay_style ............... linear\n",
      "  lr ........................... 0.0001\n",
      "  min_lr ....................... 0.0\n",
      "  warmup ....................... 0.01\n",
      "  override_lr_scheduler ........ False\n",
      "  use_checkpoint_lr_scheduler .. False\n",
      "  save ......................... None\n",
      "  save_interval ................ 5000\n",
      "  no_save_optim ................ False\n",
      "  no_save_rng .................. False\n",
      "  load ......................... None\n",
      "  no_load_optim ................ False\n",
      "  no_load_rng .................. False\n",
      "  finetune ..................... False\n",
      "  resume_dataloader ............ False\n",
      "  distributed_backend .......... nccl\n",
      "  DDP_impl ..................... local\n",
      "  local_rank ................... 0\n",
      "  adlr_autoresume .............. False\n",
      "  adlr_autoresume_interval ..... 1000\n",
      "  eval_batch_size .............. None\n",
      "  eval_iters ................... 100\n",
      "  eval_interval ................ 1000\n",
      "  eval_seq_length .............. None\n",
      "  eval_max_preds_per_seq ....... None\n",
      "  overlapping_eval ............. 32\n",
      "  cloze_eval ................... False\n",
      "  strict_lambada ............... False\n",
      "  eval_hf ...................... False\n",
      "  load_openai .................. False\n",
      "  temperature .................. 1.0\n",
      "  greedy ....................... False\n",
      "  top_p ........................ 0.0\n",
      "  top_k ........................ 0\n",
      "  out_seq_length ............... 1024\n",
      "  sample_input_file ............ \n",
      "  sample_output_file ........... \n",
      "  num_samples .................. 0\n",
      "  genfile ...................... None\n",
      "  recompute .................... False\n",
      "  model_parallel_size .......... 2\n",
      "  shuffle ...................... False\n",
      "  train_data ................... ['wikipedia']\n",
      "  use_npy_data_loader .......... False\n",
      "  train_data_path .............. \n",
      "  val_data_path ................ \n",
      "  test_data_path ............... \n",
      "  input_data_sizes_file ........ sizes.txt\n",
      "  delim ........................ ,\n",
      "  text_key ..................... sentence\n",
      "  eval_text_key ................ None\n",
      "  valid_data ................... None\n",
      "  split ........................ 949,50,1\n",
      "  test_data .................... None\n",
      "  lazy_loader .................. True\n",
      "  loose_json ................... False\n",
      "  presplit_sentences ........... True\n",
      "  num_workers .................. 2\n",
      "  tokenizer_model_type ......... bert-base-uncased\n",
      "  tokenizer_path ............... tokenizer.model\n",
      "  tokenizer_type ............... XLNetWordPieceTokenizer\n",
      "  cache_dir .................... cache\n",
      "  use_tfrecords ................ False\n",
      "  seq_length ................... 512\n",
      "  max_preds_per_seq ............ None\n",
      "  reuse_len .................... 256\n",
      "  perm_size .................... 256\n",
      "  bi_data ...................... False\n",
      "  mask_alpha ................... 6\n",
      "  mask_beta .................... 1\n",
      "  num_predict .................. 85\n",
      "  mem_len ...................... 384\n",
      "  num_epoch .................... 100\n",
      "  cuda ......................... True\n",
      "  rank ......................... 0\n",
      "  world_size ................... 4\n",
      "  dynamic_loss_scale ........... True\n",
      "> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n",
      "configuring data\n",
      "loading XLnetWordPieceTokenizer ( bert-base-uncased ) from cache_dir  cache\n",
      "---data_utils/wordpiece.py/BertTokenizer/__init__.py---\n",
      "------\n",
      "loaded bert-base-uncased\n",
      "---data_utils/wordpiece.py/BertTokenizer/__init__.py---\n",
      "initialize XLNetDataset\n",
      "ds:  <data_utils.datasets.SplitDataset object at 0x7ff28423e198>\n",
      "#####-----data_utils/datasets.py/XLNetDataset>__init__>ln(597...)-----#####\n",
      "tokenizer:  <data_utils.tokenization.XLNetWordPieceTokenizer object at 0x7ff378907fd0>\n",
      "ds:  <data_utils.datasets.SplitDataset object at 0x7ff28423e160>\n",
      "#####-----data_utils/datasets.py/XLNetDataset>__init__>ln(597...)-----#####\n",
      "tokenizer:  <data_utils.tokenization.XLNetWordPieceTokenizer object at 0x7ff378907fd0>\n",
      "ds:  <data_utils.datasets.SplitDataset object at 0x7ff28423e1d0>\n",
      "#####-----data_utils/datasets.py/XLNetDataset>__init__>ln(597...)-----#####\n",
      "tokenizer:  <data_utils.tokenization.XLNetWordPieceTokenizer object at 0x7ff378907fd0>\n",
      "<data_utils.tokenization.XLNetWordPieceTokenizer object at 0x7ff378907fd0>\n",
      "> padded vocab (size: 30522) with 198 dummy tokens (new size: 30720)\n",
      "------\n",
      "initialize XLNetDataset\n",
      "ds:  <data_utils.datasets.SplitDataset object at 0x7f876ccc7240>\n",
      "#####-----data_utils/datasets.py/XLNetDataset>__init__>ln(597...)-----#####\n",
      "tokenizer:  <data_utils.tokenization.XLNetWordPieceTokenizer object at 0x7f877676dda0>\n",
      "ds:  <data_utils.datasets.SplitDataset object at 0x7f876ccc7208>\n",
      "#####-----data_utils/datasets.py/XLNetDataset>__init__>ln(597...)-----#####\n",
      "tokenizer:  <data_utils.tokenization.XLNetWordPieceTokenizer object at 0x7f877676dda0>\n",
      "ds:  <data_utils.datasets.SplitDataset object at 0x7f876ccc7278>\n",
      "#####-----data_utils/datasets.py/XLNetDataset>__init__>ln(597...)-----#####\n",
      "tokenizer:  <data_utils.tokenization.XLNetWordPieceTokenizer object at 0x7f877676dda0>\n",
      "<data_utils.tokenization.XLNetWordPieceTokenizer object at 0x7f877676dda0>\n",
      "barrier ahead\n",
      "barrier ahead\n",
      "barrier ahead\n",
      "barrier ahead\n",
      "barrier done\n",
      "barrier done\n",
      "barrier done\n",
      "building XLNet model ...\n",
      "barrier done\n",
      " > number of parameters on model parallel rank 0: 521017\n",
      " > number of parameters on model parallel rank 1: 521017\n",
      "0\n",
      "2\n",
      "ds_batch_type:  <class 'str'>\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  239\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  141\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  47\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  140\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  10\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7f876ccc7a90>\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  10\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  97\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  9\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "ds_batch_type:  <class 'str'>\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7ff28423e9e8>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  104\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  66\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  52\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  6\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  143\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "seg_id type is\n",
      "torch.int64\n",
      "label type is\n",
      "torch.int64\n",
      "target_mapping type is\n",
      "torch.int64\n",
      "target type is\n",
      "torch.int64\n",
      "target_mask type is\n",
      "torch.int64\n",
      "perm_mask type is\n",
      "torch.int64\n",
      "input_k type is\n",
      "torch.int64\n",
      "input_q type is\n",
      "torch.int64\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  26\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  140\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  30\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  5\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "seg_id type is\n",
      "torch.int64\n",
      "label type is\n",
      "torch.int64\n",
      "target_mapping type is\n",
      "torch.int64\n",
      "target type is\n",
      "torch.int64\n",
      "ds_batch_type:  <class 'str'>\n",
      "target_mask type is\n",
      "torch.int64\n",
      "perm_mask type is\n",
      "lines type:  <class 'list'>\n",
      "torch.int64\n",
      "len_lines:  26\n",
      "input_k type is\n",
      "torch.int64\n",
      "input_q type is\n",
      "torch.int64\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "Number of  1 Step cost = 10.323997\n",
      "Number of  1 Step cost = 10.323997\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 1 took 0.5205752849578857\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7ff28423e9e8>\n",
      "seg_id type is\n",
      "torch.int64\n",
      "label type is\n",
      "torch.int64\n",
      "target_mapping type is\n",
      "torch.int64\n",
      "target type is\n",
      "torch.int64\n",
      "target_mask type is\n",
      "torch.int64\n",
      "perm_mask type is\n",
      "torch.int64\n",
      "input_k type is\n",
      "torch.int64\n",
      "input_q type is\n",
      "torch.int64\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  284\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 1 took 0.5239865779876709\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "Number of  2 Step cost = 10.320146\n",
      "Number of  2 Step cost = 10.320146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 2 took 0.11806821823120117\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7ff28423e9e8>\n",
      "seg_id type is\n",
      "torch.int64\n",
      "label type is\n",
      "torch.int64\n",
      "target_mapping type is\n",
      "torch.int64\n",
      "target type is\n",
      "torch.int64\n",
      "target_mask type is\n",
      "torch.int64\n",
      "perm_mask type is\n",
      "torch.int64\n",
      "input_k type is\n",
      "torch.int64\n",
      "input_q type is\n",
      "torch.int64\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  14\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 2 took 0.11940574645996094\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "Number of  3 Step cost = 10.318585\n",
      "Number of  3 Step cost = 10.318585\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 3 took 0.11842608451843262\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7ff28423e9e8>\n",
      "seg_id type is\n",
      "torch.int64\n",
      "label type is\n",
      "torch.int64\n",
      "target_mapping type is\n",
      "torch.int64\n",
      "target type is\n",
      "torch.int64\n",
      "target_mask type is\n",
      "torch.int64\n",
      "perm_mask type is\n",
      "torch.int64\n",
      "input_k type is\n",
      "torch.int64\n",
      "input_q type is\n",
      "torch.int64\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 3 took 0.12171530723571777\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "Number of  4 Step cost = 10.328588\n",
      "Number of  4 Step cost = 10.328588\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 4 took 0.11771845817565918\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7ff28423e9e8>\n",
      "seg_id type is\n",
      "torch.int64\n",
      "label type is\n",
      "torch.int64\n",
      "target_mapping type is\n",
      "torch.int64\n",
      "target type is\n",
      "torch.int64\n",
      "target_mask type is\n",
      "torch.int64\n",
      "perm_mask type is\n",
      "torch.int64\n",
      "input_k type is\n",
      "torch.int64\n",
      "input_q type is\n",
      "torch.int64\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  11\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 4 took 0.11744165420532227\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "ds_batch_type:  <class 'str'>\n",
      "Number of  1 Step cost = 10.327031\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  169\n",
      "Number of  1 Step cost = 10.327031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "Number of  5 Step cost = 10.323882\n",
      "Number of  5 Step cost = 10.323882\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 1 took 0.5382099151611328\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7f876ccc7a90>\n",
      "seg_id type is\n",
      "torch.int64\n",
      "label type is\n",
      "torch.int64\n",
      "target_mapping type is\n",
      "torch.int64\n",
      "target type is\n",
      "torch.int64\n",
      "target_mask type is\n",
      "torch.int64\n",
      "perm_mask type is\n",
      "torch.int64\n",
      "input_k type is\n",
      "torch.int64\n",
      "input_q type is\n",
      "torch.int64\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  40\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 1 took 0.5408217906951904\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 5 took 0.12860965728759766\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 5 took 0.13065505027770996\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7ff28423e9e8>\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "Number of  2 Step cost = 10.329951\n",
      "Number of  2 Step cost = 10.329951\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 2 took 0.13301849365234375\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 2 took 0.13377857208251953\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7f876ccc7a90>\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 448, in <module>\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  156\n",
      "    main()\n",
      "  File \"main.py\", line 335, in main\n",
      "    input_k, seg_id, target, perm_mask, target_mapping, input_q, target_mask = get_batch(train_data_iterator, timers)\n",
      "  File \"main.py\", line 124, in get_batch\n",
      "    data = next(data_iterator)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 551, in __next__\n",
      "    return self._process_next_batch(batch)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 577, in _process_next_batch\n",
      "    raise batch.exc_type(batch.exc_msg)\n",
      "TypeError: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 99, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 70, in default_collate\n",
      "    raise TypeError((error_msg_fmt.format(type(batch[0]))))\n",
      "TypeError: batch must contain tensors, numbers, dicts or lists; found <class 'NoneType'>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seg_id type is\n",
      "torch.int64\n",
      "label type is\n",
      "torch.int64\n",
      "target_mapping type is\n",
      "torch.int64\n",
      "target type is\n",
      "torch.int64\n",
      "target_mask type is\n",
      "torch.int64\n",
      "perm_mask type is\n",
      "torch.int64\n",
      "input_k type is\n",
      "torch.int64\n",
      "input_q type is\n",
      "torch.int64\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "Number of  6 Step cost = 10.319417\n",
      "Number of  6 Step cost = 10.319417\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 6 took 0.1272871494293213\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 6 took 0.1292126178741455\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7ff28423e9e8>\n",
      "seg_id type is\n",
      "torch.int64\n",
      "label type is\n",
      "torch.int64\n",
      "target_mapping type is\n",
      "torch.int64\n",
      "target type is\n",
      "torch.int64\n",
      "target_mask type is\n",
      "torch.int64\n",
      "perm_mask type is\n",
      "torch.int64\n",
      "input_k type is\n",
      "torch.int64\n",
      "input_q type is\n",
      "torch.int64\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  101\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  290\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "Number of  7 Step cost = 10.322758\n",
      "Number of  7 Step cost = 10.322758\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 7 took 0.13358592987060547\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7ff28423e9e8>\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 7 took 0.13401103019714355\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "seg_id type is\n",
      "torch.int64\n",
      "label type is\n",
      "torch.int64\n",
      "target_mapping type is\n",
      "torch.int64\n",
      "target type is\n",
      "torch.int64\n",
      "target_mask type is\n",
      "torch.int64\n",
      "perm_mask type is\n",
      "torch.int64\n",
      "input_k type is\n",
      "torch.int64\n",
      "input_q type is\n",
      "torch.int64\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  50\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "Number of  8 Step cost = 10.313424\n",
      "Number of  8 Step cost = 10.313424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 8 took 0.11896491050720215\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7ff28423e9e8>\n",
      "seg_id type is\n",
      "torch.int64\n",
      "label type is\n",
      "torch.int64\n",
      "target_mapping type is\n",
      "torch.int64\n",
      "target type is\n",
      "torch.int64\n",
      "target_mask type is\n",
      "#################\n",
      "torch.int64\n",
      "perm_mask type is\n",
      "@@@@@@@@@@@@@@@@\n",
      "torch.int64\n",
      "this num_step 8 took 0.11957550048828125\n",
      "input_k type is\n",
      "#################\n",
      "torch.int64\n",
      "@@@@@@@@@@@@@@@@\n",
      "input_q type is\n",
      "torch.int64\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "Number of  9 Step cost = 10.310951\n",
      "Number of  9 Step cost = 10.310951\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 9 took 0.11647510528564453\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 9 took 0.11835861206054688\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7ff28423e9e8>\n",
      "seg_id type is\n",
      "torch.int64\n",
      "label type is\n",
      "torch.int64\n",
      "target_mapping type is\n",
      "torch.int64\n",
      "target type is\n",
      "torch.int64\n",
      "target_mask type is\n",
      "torch.int64\n",
      "perm_mask type is\n",
      "torch.int64\n",
      "input_k type is\n",
      "torch.int64\n",
      "input_q type is\n",
      "torch.int64\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  102\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "Number of  10 Step cost = 10.319149\n",
      "Number of  10 Step cost = 10.319149\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  28\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 10 took 0.12586665153503418\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7ff28423e9e8>\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 10 took 0.12756824493408203\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "seg_id type is\n",
      "torch.int64\n",
      "label type is\n",
      "torch.int64\n",
      "target_mapping type is\n",
      "torch.int64\n",
      "target type is\n",
      "torch.int64\n",
      "target_mask type is\n",
      "torch.int64\n",
      "perm_mask type is\n",
      "torch.int64\n",
      "input_k type is\n",
      "torch.int64\n",
      "input_q type is\n",
      "torch.int64\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  8\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "Number of  11 Step cost = 10.317413\n",
      "Number of  11 Step cost = 10.317413\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 11 took 0.12100481986999512\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 11 took 0.12091445922851562\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7ff28423e9e8>\n",
      "seg_id type is\n",
      "torch.int64\n",
      "label type is\n",
      "torch.int64\n",
      "target_mapping type is\n",
      "torch.int64\n",
      "target type is\n",
      "torch.int64\n",
      "target_mask type is\n",
      "torch.int64\n",
      "perm_mask type is\n",
      "torch.int64\n",
      "input_k type is\n",
      "torch.int64\n",
      "input_q type is\n",
      "torch.int64\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  149\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "Number of  12 Step cost = 10.311995\n",
      "Number of  12 Step cost = 10.311995\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 12 took 0.10854077339172363\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7ff28423e9e8>\n",
      "seg_id type is\n",
      "torch.int64\n",
      "label type is\n",
      "torch.int64\n",
      "target_mapping type is\n",
      "torch.int64\n",
      "target type is\n",
      "torch.int64\n",
      "target_mask type is\n",
      "torch.int64\n",
      "perm_mask type is\n",
      "torch.int64\n",
      "input_k type is\n",
      "torch.int64\n",
      "input_q type is\n",
      "torch.int64\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  212\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 12 took 0.11167192459106445\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "Number of  13 Step cost = 10.303221\n",
      "Number of  13 Step cost = 10.303221\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 13 took 0.12204551696777344\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 13 took 0.12500715255737305\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7ff28423e9e8>\n",
      "seg_id type is\n",
      "torch.int64\n",
      "label type is\n",
      "torch.int64\n",
      "target_mapping type is\n",
      "torch.int64\n",
      "target type is\n",
      "torch.int64\n",
      "target_mask type is\n",
      "torch.int64\n",
      "perm_mask type is\n",
      "torch.int64\n",
      "input_k type is\n",
      "torch.int64\n",
      "input_q type is\n",
      "torch.int64\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "torch.Size([512, 1]) torch.Size([512, 1, 32]) torch.Size([15261, 32]) a bC\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "#####-----integrate-paralllel/Megatron-LM-mp/xlnet/xlnet.py/forward>(ln 672...)-----#####\n",
      "model loop\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "torch.Size([512, 1, 32]) CAT torch.Size([4, 8])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "QQQQQQQQQQQQ torch.Size([512, 1, 4, 4]) torch.Size([4, 4]) torch.Size([512, 1, 4, 4])\n",
      "Number of  14 Step cost = 10.305107\n",
      "Number of  14 Step cost = 10.305107\n",
      "#####-----Megatron-LM-mp/xlnet/data_utils/datasets.py/XLNetDataset/__getitem>ln(669...)-----#####\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "this num_step 14 took 0.11431694030761719\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "data_iterator:  <torch.utils.data.dataloader._DataLoaderIter object at 0x7ff28423e9e8>\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 448, in <module>\n",
      "ds_batch_type:  <class 'str'>\n",
      "lines type:  <class 'list'>\n",
      "len_lines:  171\n",
      "    main()\n",
      "  File \"main.py\", line 335, in main\n",
      "    input_k, seg_id, target, perm_mask, target_mapping, input_q, target_mask = get_batch(train_data_iterator, timers)\n",
      "  File \"main.py\", line 124, in get_batch\n",
      "    data = next(data_iterator)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 537, in __next__\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "    return self._process_next_batch(batch)\n",
      "this num_step 14 took 0.11572098731994629\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 577, in _process_next_batch\n",
      "#################\n",
      "@@@@@@@@@@@@@@@@\n",
      "    raise batch.exc_type(batch.exc_msg)\n",
      "TypeError: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 99, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 70, in default_collate\n",
      "    raise TypeError((error_msg_fmt.format(type(batch[0]))))\n",
      "TypeError: batch must contain tensors, numbers, dicts or lists; found <class 'NoneType'>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/distributed/launch.py\", line 235, in <module>\n",
      "    main()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/distributed/launch.py\", line 231, in main\n",
      "    cmd=process.args)\n",
      "subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '--model-parallel-size', '2', '--distributed-backend', 'nccl', '--batch-size', '1', '--seq-length', '512', '--train-data', 'wikipedia', '--lazy-loader', '--tokenizer-type', 'XLNetWordPieceTokenizer', '--tokenizer-model-type', 'bert-base-uncased', '--presplit-sentences', '--cache-dir', 'cache', '--split', '949,50,1', '--weight-decay', '1e-2', '--clip-grad', '1.0', '--warmup', '.01']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/megatron/integrate-paralllel/Megatron-LM-mp/xlnet/\n",
    "#first edit\n",
    "!bash scripts/pretrain_xlnet_model_parallel.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= 1\n",
      "local 1\n",
      "using world size: 2 and model-parallel size: 2 \n",
      " > using dynamic loss scaling\n",
      "device= 0\n",
      "local 0\n",
      "1 range(0, 2)\n",
      "barrier ahead\n",
      "> initializing model parallel with size 2\n",
      "0 range(0, 2)\n",
      "Pretrain GPT2 model\n",
      "arguments:\n",
      "  pretrained_bert .............. False\n",
      "  attention_dropout ............ 0.1\n",
      "  num_attention_heads .......... 16\n",
      "  hidden_size .................. 1024\n",
      "  intermediate_size ............ None\n",
      "  num_layers ................... 24\n",
      "  layernorm_epsilon ............ 1e-05\n",
      "  hidden_dropout ............... 0.1\n",
      "  max_position_embeddings ...... 1024\n",
      "  vocab_size ................... 30522\n",
      "  deep_init .................... False\n",
      "  make_vocab_size_divisible_by . 128\n",
      "  fp16 ......................... True\n",
      "  fp32_embedding ............... False\n",
      "  fp32_layernorm ............... False\n",
      "  fp32_tokentypes .............. False\n",
      "  fp32_allreduce ............... False\n",
      "  hysteresis ................... 2\n",
      "  loss_scale ................... None\n",
      "  loss_scale_window ............ 1000\n",
      "  min_scale .................... 1\n",
      "  batch_size ................... 8\n",
      "  weight_decay ................. 0.01\n",
      "  checkpoint_activations ....... True\n",
      "  checkpoint_num_layers ........ 1\n",
      "  clip_grad .................... 1.0\n",
      "  train_iters .................. 1\n",
      "  log_interval ................. 100\n",
      "  exit_interval ................ None\n",
      "  tensorboard_dir .............. None\n",
      "  seed ......................... 1234\n",
      "  reset_position_ids ........... False\n",
      "  reset_attention_mask ......... False\n",
      "  eod_mask_loss ................ False\n",
      "  lr_decay_iters ............... None\n",
      "  lr_decay_style ............... cosine\n",
      "  lr ........................... 0.00015\n",
      "  min_lr ....................... 0.0\n",
      "  warmup ....................... 0.01\n",
      "  override_lr_scheduler ........ False\n",
      "  use_checkpoint_lr_scheduler .. False\n",
      "  save ......................... checkpoints/gpt2_345m_mp2\n",
      "  save_interval ................ 5000\n",
      "  no_save_optim ................ False\n",
      "  no_save_rng .................. False\n",
      "  load ......................... checkpoints/gpt2_345m_mp2\n",
      "  no_load_optim ................ False\n",
      "  no_load_rng .................. False\n",
      "  finetune ..................... False\n",
      "  resume_dataloader ............ True\n",
      "  distributed_backend .......... nccl\n",
      "  DDP_impl ..................... local\n",
      "  local_rank ................... 0\n",
      "  adlr_autoresume .............. False\n",
      "  adlr_autoresume_interval ..... 1000\n",
      "  eval_batch_size .............. None\n",
      "  eval_iters ................... 100\n",
      "  eval_interval ................ 1000\n",
      "  eval_seq_length .............. None\n",
      "  eval_max_preds_per_seq ....... None\n",
      "  overlapping_eval ............. 32\n",
      "  cloze_eval ................... False\n",
      "  strict_lambada ............... False\n",
      "  eval_hf ...................... False\n",
      "  load_openai .................. False\n",
      "  temperature .................. 1.0\n",
      "  greedy ....................... False\n",
      "  top_p ........................ 0.0\n",
      "  top_k ........................ 0\n",
      "  out_seq_length ............... 1024\n",
      "  sample_input_file ............ \n",
      "  sample_output_file ........... \n",
      "  num_samples .................. 0\n",
      "  genfile ...................... None\n",
      "  recompute .................... False\n",
      "  model_parallel_size .......... 2\n",
      "  shuffle ...................... False\n",
      "  train_data ................... ['wikipedia']\n",
      "  use_npy_data_loader .......... False\n",
      "  train_data_path .............. \n",
      "  val_data_path ................ \n",
      "  test_data_path ............... \n",
      "  input_data_sizes_file ........ sizes.txt\n",
      "  delim ........................ ,\n",
      "  text_key ..................... sentence\n",
      "  eval_text_key ................ None\n",
      "  valid_data ................... None\n",
      "  split ........................ 949,50,1\n",
      "  test_data .................... None\n",
      "  lazy_loader .................. True\n",
      "  loose_json ................... False\n",
      "  presplit_sentences ........... False\n",
      "  num_workers .................. 2\n",
      "  tokenizer_model_type ......... bert-large-uncased\n",
      "  tokenizer_path ............... tokenizer.model\n",
      "  tokenizer_type ............... GPT2BPETokenizer\n",
      "  cache_dir .................... cache\n",
      "  use_tfrecords ................ False\n",
      "  seq_length ................... 1024\n",
      "  max_preds_per_seq ............ None\n",
      "  cuda ......................... True\n",
      "  rank ......................... 0\n",
      "  world_size ................... 2\n",
      "  dynamic_loss_scale ........... True\n",
      "barrier ahead\n",
      "barrier done\n",
      "barrier done\n",
      "> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n",
      "configuring data\n"
     ]
    }
   ],
   "source": [
    "!bash scripts/pretrain_gpt2_model_parallel.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4038f445a699>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_available_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlocal_device_protos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocal_device_protos\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'GPU'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
